{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras 函数api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:10:09.951431Z",
     "start_time": "2019-12-08T10:10:09.947431Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install pydot\n",
    "#!sudo apt-get install graphvizf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:10:15.293737Z",
     "start_time": "2019-12-08T10:10:09.956431Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from keras.utils.vis_utils import model_to_dot\n",
    "#keras.utils.vis_utils.pydot = pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1构建简单的网络\n",
    "### 1.1创建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:10:16.822824Z",
     "start_time": "2019-12-08T10:10:15.294737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = keras.Input(shape=(784,), name='img')\n",
    "h1 = layers.Dense(32, activation='relu')(inputs)\n",
    "h2 = layers.Dense(32, activation='relu')(h1)\n",
    "outputs = layers.Dense(10, activation='softmax')(h2)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')\n",
    "\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, 'mnist_model.png')\n",
    "keras.utils.plot_model(model, 'model_info.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2训练、验证及测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:10:17.303852Z",
     "start_time": "2019-12-08T10:10:16.823824Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') /255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') /255\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "             loss='sparse_categorical_crossentropy', # 直接填api，后面会报错\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:10:33.568782Z",
     "start_time": "2019-12-08T10:10:17.304852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 4s 82us/sample - loss: 0.4402 - accuracy: 0.8769 - val_loss: 0.2320 - val_accuracy: 0.9304\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 3s 64us/sample - loss: 0.2145 - accuracy: 0.9367 - val_loss: 0.1837 - val_accuracy: 0.9460\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 3s 65us/sample - loss: 0.1714 - accuracy: 0.9504 - val_loss: 0.1627 - val_accuracy: 0.9538\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 3s 64us/sample - loss: 0.1472 - accuracy: 0.9566 - val_loss: 0.1442 - val_accuracy: 0.9590\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 3s 63us/sample - loss: 0.1269 - accuracy: 0.9628 - val_loss: 0.1373 - val_accuracy: 0.9594\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=64, epochs=5, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:10:34.233820Z",
     "start_time": "2019-12-08T10:10:33.569782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.1325945740096271\n",
      "test acc: 0.9599\n"
     ]
    }
   ],
   "source": [
    "test_scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('test loss:', test_scores[0])\n",
    "print('test acc:', test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3模型保持和序列化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:10:34.579840Z",
     "start_time": "2019-12-08T10:10:34.236820Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('model_save.h5')\n",
    "del model\n",
    "model = keras.models.load_model('model_save.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 使用共享网络创建多个模型\n",
    "在函数API中，通过在图层图中指定其输入和输出来创建模型。 这意味着可以使用单个图层图来生成多个模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:10:34.744849Z",
     "start_time": "2019-12-08T10:10:34.581840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 18,672\n",
      "Trainable params: 18,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 6, 6, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 26, 26, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 28,241\n",
      "Trainable params: 28,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 编码器网络和自编码器网络\n",
    "\n",
    "encode_input = keras.Input(shape=(28,28,1), name='img')\n",
    "h1 = layers.Conv2D(16, 3, activation='relu')(encode_input)\n",
    "h1 = layers.Conv2D(32, 3, activation='relu')(h1)\n",
    "h1 = layers.MaxPool2D(3)(h1)\n",
    "h1 = layers.Conv2D(32, 3, activation='relu')(h1)\n",
    "h1 = layers.Conv2D(16, 3, activation='relu')(h1)\n",
    "encode_output = layers.GlobalMaxPool2D()(h1)\n",
    "\n",
    "encode_model = keras.Model(inputs=encode_input, outputs=encode_output, name='encoder')\n",
    "encode_model.summary()\n",
    "\n",
    "h2 = layers.Reshape((4, 4, 1))(encode_output)\n",
    "h2 = layers.Conv2DTranspose(16, 3, activation='relu')(h2)\n",
    "h2 = layers.Conv2DTranspose(32, 3, activation='relu')(h2)\n",
    "h2 = layers.UpSampling2D(3)(h2)\n",
    "h2 = layers.Conv2DTranspose(16, 3, activation='relu')(h2)\n",
    "decode_output = layers.Conv2DTranspose(1, 3, activation='relu')(h2)\n",
    "\n",
    "autoencoder = keras.Model(inputs=encode_input, outputs=decode_output, name='autoencoder')\n",
    "autoencoder.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以把整个模型，当作一层网络使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:10:35.092869Z",
     "start_time": "2019-12-08T10:10:34.747849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "src_img (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 18,672\n",
      "Trainable params: 18,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_img (InputLayer)     [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 6, 6, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 26, 26, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 9,569\n",
      "Trainable params: 9,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 16)                18672     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         9569      \n",
      "=================================================================\n",
      "Total params: 28,241\n",
      "Trainable params: 28,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encode_input = keras.Input(shape=(28,28,1), name='src_img')\n",
    "h1 = layers.Conv2D(16, 3, activation='relu')(encode_input)\n",
    "h1 = layers.Conv2D(32, 3, activation='relu')(h1)\n",
    "h1 = layers.MaxPool2D(3)(h1)\n",
    "h1 = layers.Conv2D(32, 3, activation='relu')(h1)\n",
    "h1 = layers.Conv2D(16, 3, activation='relu')(h1)\n",
    "encode_output = layers.GlobalMaxPool2D()(h1)\n",
    "\n",
    "encode_model = keras.Model(inputs=encode_input, outputs=encode_output, name='encoder')\n",
    "encode_model.summary()\n",
    "\n",
    "decode_input = keras.Input(shape=(16,), name='encoded_img')\n",
    "h2 = layers.Reshape((4, 4, 1))(decode_input)\n",
    "h2 = layers.Conv2DTranspose(16, 3, activation='relu')(h2)\n",
    "h2 = layers.Conv2DTranspose(32, 3, activation='relu')(h2)\n",
    "h2 = layers.UpSampling2D(3)(h2)\n",
    "h2 = layers.Conv2DTranspose(16, 3, activation='relu')(h2)\n",
    "decode_output = layers.Conv2DTranspose(1, 3, activation='relu')(h2)\n",
    "decode_model = keras.Model(inputs=decode_input, outputs=decode_output, name='decoder')\n",
    "decode_model.summary()\n",
    "\n",
    "autoencoder_input = keras.Input(shape=(28,28,1), name='img')\n",
    "h3 = encode_model(autoencoder_input)\n",
    "autoencoder_output = decode_model(h3)\n",
    "autoencoder = keras.Model(inputs=autoencoder_input, outputs=autoencoder_output,\n",
    "                          name='autoencoder')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.复杂网络结构构建\n",
    "### 3.1多输入与多输出网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:10:35.580897Z",
     "start_time": "2019-12-08T10:10:35.094869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "body (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 64)     128000      title[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 64)     128000      body[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          98816       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           12416       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tag (InputLayer)                [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 172)          0           lstm_1[0][0]                     \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 tag[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "priority (Dense)                (None, 1)            173         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "department (Dense)              (None, 4)            692         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 368,097\n",
      "Trainable params: 368,097\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "# 构建一个根据文档内容、标签和标题，预测文档优先级和执行部门的网络\n",
    "# 超参\n",
    "num_words = 2000\n",
    "num_tags = 12\n",
    "num_departments = 4\n",
    "\n",
    "# 输入\n",
    "body_input = keras.Input(shape=(None,), name='body')\n",
    "title_input = keras.Input(shape=(None,), name='title')\n",
    "tag_input = keras.Input(shape=(num_tags,), name='tag')\n",
    "\n",
    "# 嵌入层\n",
    "body_feat = layers.Embedding(num_words, 64)(body_input)\n",
    "title_feat = layers.Embedding(num_words, 64)(title_input)\n",
    "\n",
    "# 特征提取层\n",
    "body_feat = layers.LSTM(32)(body_feat)\n",
    "title_feat = layers.LSTM(128)(title_feat)\n",
    "features = layers.concatenate([title_feat,body_feat, tag_input])\n",
    "\n",
    "# 分类层\n",
    "priority_pred = layers.Dense(1, activation='sigmoid', name='priority')(features)\n",
    "department_pred = layers.Dense(num_departments, activation='softmax', name='department')(features)\n",
    "\n",
    "\n",
    "# 构建模型\n",
    "model = keras.Model(inputs=[body_input, title_input, tag_input],\n",
    "                    outputs=[priority_pred, department_pred])\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, 'multi_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:10:52.893887Z",
     "start_time": "2019-12-08T10:10:35.584897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1280 samples\n",
      "Epoch 1/5\n",
      "1280/1280 [==============================] - 14s 11ms/sample - loss: 1.2902 - priority_loss: 0.7139 - department_loss: 2.8814\n",
      "Epoch 2/5\n",
      "1280/1280 [==============================] - 1s 634us/sample - loss: 1.2662 - priority_loss: 0.6976 - department_loss: 2.8429\n",
      "Epoch 3/5\n",
      "1280/1280 [==============================] - 1s 640us/sample - loss: 1.2627 - priority_loss: 0.6988 - department_loss: 2.8193\n",
      "Epoch 4/5\n",
      "1280/1280 [==============================] - 1s 650us/sample - loss: 1.2549 - priority_loss: 0.6967 - department_loss: 2.7908\n",
      "Epoch 5/5\n",
      "1280/1280 [==============================] - 1s 645us/sample - loss: 1.2518 - priority_loss: 0.6961 - department_loss: 2.7784\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "             loss={'priority': 'binary_crossentropy',\n",
    "                  'department': 'categorical_crossentropy'},\n",
    "             loss_weights=[1., 0.2])\n",
    "\n",
    "import numpy as np\n",
    "# 载入输入数据\n",
    "title_data = np.random.randint(num_words, size=(1280, 10))\n",
    "body_data = np.random.randint(num_words, size=(1280, 100))\n",
    "tag_data = np.random.randint(2, size=(1280, num_tags)).astype('float32')\n",
    "# 标签\n",
    "priority_label = np.random.random(size=(1280, 1))\n",
    "department_label = np.random.randint(2, size=(1280, num_departments))\n",
    "# 训练\n",
    "history = model.fit(\n",
    "    {'title': title_data, 'body':body_data, 'tag':tag_data},\n",
    "    {'priority':priority_label, 'department':department_label},\n",
    "    batch_size=32,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2小型残差网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:10:53.035895Z",
     "start_time": "2019-12-08T10:10:52.895887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"small resnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 30, 30, 32)   896         img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 28, 28, 64)   18496       conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 9, 9, 64)     0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 9, 9, 64)     36928       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 9, 9, 64)     36928       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 9, 9, 64)     0           conv2d_11[0][0]                  \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 9, 9, 64)     36928       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 9, 9, 64)     36928       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 9, 9, 64)     0           conv2d_13[0][0]                  \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 7, 7, 64)     36928       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalM (None, 64)           0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          16640       global_max_pooling2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           2570        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 223,242\n",
      "Trainable params: 223,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32,32,3), name='img')\n",
    "h1 = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "h1 = layers.Conv2D(64, 3, activation='relu')(h1)\n",
    "block1_out = layers.MaxPooling2D(3)(h1)\n",
    "\n",
    "h2 = layers.Conv2D(64, 3, activation='relu', padding='same')(block1_out)\n",
    "h2 = layers.Conv2D(64, 3, activation='relu', padding='same')(h2)\n",
    "block2_out = layers.add([h2, block1_out])\n",
    "\n",
    "h3 = layers.Conv2D(64, 3, activation='relu', padding='same')(block2_out)\n",
    "h3 = layers.Conv2D(64, 3, activation='relu', padding='same')(h3)\n",
    "block3_out = layers.add([h3, block2_out])\n",
    "\n",
    "h4 = layers.Conv2D(64, 3, activation='relu')(block3_out)\n",
    "h4 = layers.GlobalMaxPool2D()(h4)\n",
    "h4 = layers.Dense(256, activation='relu')(h4)\n",
    "h4 = layers.Dropout(0.5)(h4)\n",
    "outputs = layers.Dense(10, activation='softmax')(h4)\n",
    "\n",
    "model = keras.Model(inputs, outputs, name='small resnet')\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, 'small_resnet_model.png', show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:15:45.252609Z",
     "start_time": "2019-12-08T10:10:53.037896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      " 12279808/170498071 [=>............................] - ETA: 1:02:10"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-6245c9af69d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcifar10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\datasets\\cifar10.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m       \u001b[0muntar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m       \u001b[0mfile_hash\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m       '6d958be074577803d12ecdefd02955f39262c83c16fe9348329d7fe0b5c001ce')\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m   \u001b[0mnum_train_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m                 \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1069\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1071\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    927\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 929\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    930\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = y_train.astype('float32') / 255\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['acc'])\n",
    "model.fit(x_train, y_train,\n",
    "         batch_size=64,\n",
    "         epochs=1,\n",
    "         validation_split=0.2)\n",
    "\n",
    "#model.predict(x_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.共享网络层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:15:45.255609Z",
     "start_time": "2019-12-08T10:10:09.782Z"
    }
   },
   "outputs": [],
   "source": [
    "share_embedding = layers.Embedding(1000, 64)\n",
    "\n",
    "input1 = keras.Input(shape=(None,), dtype='int32')\n",
    "input2 = keras.Input(shape=(None,), dtype='int32')\n",
    "\n",
    "feat1 = share_embedding(input1)\n",
    "feat2 = share_embedding(input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.模型复用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:15:45.257610Z",
     "start_time": "2019-12-08T10:10:09.790Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "vgg16=VGG16()\n",
    "\n",
    "feature_list = [layer.output for layer in vgg16.layers]\n",
    "feat_ext_model = keras.Model(inputs=vgg16.input, outputs=feature_list)\n",
    "\n",
    "img = np.random.random((1, 224, 224, 3).astype('float32'))\n",
    "ext_features = feat_ext_model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.自定义网络层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:15:45.258610Z",
     "start_time": "2019-12-08T10:10:09.795Z"
    }
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import tensorflow.keras as keras\n",
    "class MyDense(layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(MyDense, self).__init__()\n",
    "        self.units = units\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {'units': self.units}\n",
    "    \n",
    "inputs = keras.Input((4,))\n",
    "outputs = MyDense(10)(inputs)\n",
    "model = keras.Model(inputs, outputs)\n",
    "config = model.get_config()\n",
    "new_model = keras.Model.from_config(\n",
    "config, custom_objects={'MyDense':MyDense}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:15:45.259610Z",
     "start_time": "2019-12-08T10:10:09.799Z"
    }
   },
   "outputs": [],
   "source": [
    "# 在自定义网络层调用其他网络层\n",
    "\n",
    "# 超参\n",
    "time_step = 10\n",
    "batch_size = 32\n",
    "hidden_dim = 32\n",
    "inputs_dim = 5\n",
    "\n",
    "# 网络\n",
    "class MyRnn(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MyRnn, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.projection1 = layers.Dense(units=hidden_dim, activation='relu')\n",
    "        self.projection2 = layers.Dense(units=hidden_dim, activation='relu')\n",
    "        self.classifier = layers.Dense(1, activation='sigmoid')\n",
    "    def call(self, inputs):\n",
    "        outs = []\n",
    "        states = tf.zeros(shape=[inputs.shape[0], self.hidden_dim])\n",
    "        for t in range(inputs.shape[1]):\n",
    "            x = inputs[:,t,:]\n",
    "            h = self.projection1(x)\n",
    "            y = h + self.projection2(states)\n",
    "            states = y\n",
    "            outs.append(y)\n",
    "        # print(outs)\n",
    "        features = tf.stack(outs, axis=1)\n",
    "        print(features.shape)\n",
    "        return self.classifier(features)\n",
    "\n",
    "# 构建网络\n",
    "inputs = keras.Input(batch_shape=(batch_size, time_step, inputs_dim))\n",
    "x = layers.Conv1D(32, 3)(inputs)\n",
    "print(x.shape)\n",
    "outputs = MyRnn()(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "rnn_model = MyRnn()\n",
    "_ = rnn_model(tf.zeros((1, 10, 5)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:15:45.260610Z",
     "start_time": "2019-12-08T10:10:09.805Z"
    }
   },
   "outputs": [],
   "source": [
    "# 简单的卷积神经网络\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "inputs = keras.Input(shape=(32,32,3), name='img')\n",
    "h1 = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "h2 = layers.Conv2D(64, 3, activation='relu')(h1)\n",
    "h3 = layers.MaxPooling2D(3)(h2)\n",
    "h3 = layers.Flatten()(h3)\n",
    "h4 = layers.Dense(256, activation='relu')(h3)\n",
    "h4 = layers.Dropout(0.5)(h4)\n",
    "outputs = layers.Dense(10, activation='softmax')(h4)\n",
    "\n",
    "model = keras.Model(inputs, outputs, name='small resnet')\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, 'small_resnet_model.png', show_shapes=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T10:15:45.260610Z",
     "start_time": "2019-12-08T10:10:09.809Z"
    }
   },
   "outputs": [],
   "source": [
    "keras.layers.GlobalMaxPool1D\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = y_train.astype('float32') / 255\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['acc'])\n",
    "model.fit(x_train, y_train,\n",
    "         batch_size=64,\n",
    "         epochs=1,\n",
    "         validation_split=0.2)\n",
    "\n",
    "#model.predict(x_test, batch_size=32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
