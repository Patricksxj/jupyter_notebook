{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T03:09:23.086499Z",
     "start_time": "2020-02-22T03:09:22.880294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.graphx.{Graph, GraphLoader, VertexId, VertexRDD}\r\n",
       "import org.apache.spark.rdd.RDD\r\n",
       "import org.apache.spark.{SparkConf, SparkContext}\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.graphx.{Graph, GraphLoader, VertexId, VertexRDD}\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.{SparkConf, SparkContext}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T03:11:19.873997Z",
     "start_time": "2020-02-22T03:11:19.827995Z"
    }
   },
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "13: error: not found: type VertexRDD\r",
     "output_type": "error",
     "traceback": [
      "<console>:13: error: not found: type VertexRDD\r",
      "         val vertices: VertexRDD[VD]\r",
      "                       ^",
      "<console>:14: error: not found: type EdgeRDD\r",
      "         val edges: EdgeRDD[ED]\r",
      "                    ^",
      ""
     ]
    }
   ],
   "source": [
    "class Graph[VD, ED] {\n",
    "  val vertices: VertexRDD[VD]\n",
    "  val edges: EdgeRDD[ED]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T03:04:56.670243Z",
     "start_time": "2020-02-22T03:04:56.579238Z"
    }
   },
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "32: error: not found: type VertexRDD\r",
     "output_type": "error",
     "traceback": [
      "<console>:32: error: not found: type VertexRDD\r",
      "         val vertices: VertexRDD[VD]\r",
      "                       ^",
      "<console>:45: error: not found: type EdgeRDD\r",
      "         val edges: EdgeRDD[ED]\r",
      "                    ^",
      "<console>:63: error: not found: type RDD\r",
      "         val triplets: RDD[EdgeTriplet[VD, ED]]\r",
      "                       ^",
      ""
     ]
    }
   ],
   "source": [
    "/**\n",
    "   * An RDD containing the vertices and their associated attributes.\n",
    "   *\n",
    "   * @note vertex ids are unique.\n",
    "   * @return an RDD containing the vertices in this graph\n",
    "   */\n",
    "  val vertices: VertexRDD[VD]\n",
    "\n",
    "  /**\n",
    "   * An RDD containing the edges and their associated attributes.  The entries in the RDD contain\n",
    "   * just the source id and target id along with the edge data.\n",
    "   *\n",
    "   * @return an RDD containing the edges in this graph\n",
    "   *\n",
    "   * @see `Edge` for the edge type.\n",
    "   * @see `Graph#triplets` to get an RDD which contains all the edges\n",
    "   * along with their vertex data.\n",
    "   *\n",
    "   */\n",
    "  val edges: EdgeRDD[ED]\n",
    "\n",
    "  /**\n",
    "   * An RDD containing the edge triplets, which are edges along with the vertex data associated with\n",
    "   * the adjacent vertices. The caller should use [[edges]] if the vertex data are not needed, i.e.\n",
    "   * if only the edge data and adjacent vertex ids are needed.\n",
    "   *\n",
    "   * @return an RDD containing edge triplets\n",
    "   *\n",
    "   * @example This operation might be used to evaluate a graph\n",
    "   * coloring where we would like to check that both vertices are a\n",
    "   * different color.\n",
    "   * {{{\n",
    "   * type Color = Int\n",
    "   * val graph: Graph[Color, Int] = GraphLoader.edgeListFile(\"hdfs://file.tsv\")\n",
    "   * val numInvalid = graph.triplets.map(e => if (e.src.data == e.dst.data) 1 else 0).sum\n",
    "   * }}}\n",
    "   */\n",
    "  val triplets: RDD[EdgeTriplet[VD, ED]]\n",
    "\n",
    "  /**\n",
    "   * Caches the vertices and edges associated with this graph at the specified storage level,\n",
    "   * ignoring any target storage levels previously set.\n",
    "   *\n",
    "   * @param newLevel the level at which to cache the graph.\n",
    "   *\n",
    "   * @return A reference to this graph for convenience.\n",
    "   */\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val sc: SparkContext\n",
    "val users: RDD[(VertexId, (String, String))] =\n",
    "sc.parallelize(Array(\n",
    "                        (3L, (\"rxin\", \"student\")), \n",
    "                        (7L, (\"jgonzal\", \"postdoc\")),\n",
    "                        (5L, (\"franklin\", \"prof\")), \n",
    "                        (2L, (\"istoica\", \"prof\"))\n",
    "            ))\n",
    "val relationships: RDD[Edge[String]] = sc.parallelize(Array(\n",
    "                    Edge(3L, 7L, \"collab\"),    \n",
    "                    Edge(5L, 3L, \"advisor\"),\n",
    "                    Edge(2L, 5L, \"colleague\"), \n",
    "                    Edge(5L, 7L, \"pi\")\n",
    "                ))\n",
    "val defaultUser = (\"John Doe\", \"Missing\")\n",
    "\n",
    "val graph = Graph(users, relationships, defaultUser)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object GraphTest {\n",
    "  def main(args: Array[String]): Unit = {\n",
    "    val conf: SparkConf = new SparkConf().setAppName(this.getClass.getSimpleName).setMaster(\"local\")\n",
    "    val sc: SparkContext = new SparkContext(conf)\n",
    "    //读取followers.txt文件创建图\n",
    "    val graph: Graph[Int, Int] = GraphLoader.edgeListFile(sc,\"F:\\\\followers.txt\")\n",
    "    //计算连通体\n",
    "    val components: Graph[VertexId, Int] = graph.connectedComponents()\n",
    "    val vertices: VertexRDD[VertexId] = components.vertices\n",
    "    /**\n",
    "      * vertices：\n",
    "      * (4,1)\n",
    "      * (1,1)\n",
    "      * (6,3)\n",
    "      * (3,3)\n",
    "      * (7,3)\n",
    "      * (2,1)\n",
    "      * 是一个tuple类型，key分别为所有的顶点id，value为key所在的连通体id(连通体中顶点id最小值)\n",
    "      */\n",
    "    //读取users.txt文件转化为(key,value)形式\n",
    "    val users: RDD[(VertexId, String)] = sc.textFile(\"F:\\\\users.txt\").map(line => {\n",
    "      val fields: Array[String] = line.split(\",\")\n",
    "      (fields(0).toLong, fields(1))\n",
    "    })\n",
    "    /**\n",
    "      * users:\n",
    "      * (1,BarackObama)\n",
    "      * (2,ladygaga)\n",
    "      * (3,jeresig)\n",
    "      * (4,justinbieber)\n",
    "      * (6,matei_zaharia)\n",
    "      * (7,odersky)\n",
    "      * (8,anonsys)\n",
    "      */\n",
    "    users.join(vertices).map{\n",
    "      case(id,(username,vertices))=>(vertices,username)\n",
    "    }.groupByKey().map(t=>{\n",
    "      t._1+\"->\"+t._2.mkString(\",\")\n",
    "    }).foreach(println(_))\n",
    "    /**\n",
    "      * 得到结果为：\n",
    "      * 1->justinbieber,BarackObama,ladygaga\n",
    "      * 3->matei_zaharia,jeresig,odersky\n",
    "      */\n",
    "  }\n",
    " \n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
