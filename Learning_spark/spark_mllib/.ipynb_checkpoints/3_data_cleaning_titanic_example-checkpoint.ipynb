{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[2]\") \\\n",
    "   .appName(\"test\") \\\n",
    "   .enableHiveSupport() \\\n",
    "   .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = spark.read.csv(\"../data/titanic_train.csv\", header=True)\n",
    "df_test = spark.read.csv(\"../data/titanic_test.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: string, Survived: string, Pclass: string, Name: string, Sex: string, Age: string, SibSp: string, Parch: string, Ticket: string, Fare: string, Cabin: string, Embarked: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|  22|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|  38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|  26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|  35|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|  35|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|  54|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|   2|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|  27|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|  14|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|   4|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|  58|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|  20|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|  39|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|  14|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|  55|    0|    0|          248706|     16| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|   2|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|     13| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|  31|    1|    0|          345763|     18| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, col\n",
    "df_train = df_train.withColumn('Mark',lit('train'))\n",
    "df_test = (df_test.withColumn('Survived',lit(0))\n",
    "                  .withColumn('Mark',lit('test')))\n",
    "\n",
    "df_test = df_test[df_train.columns]\n",
    "## Append Test data to Train data\n",
    "df = df_train.unionAll(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: string, Survived: string, Pclass: string, Name: string, Sex: string, Age: string, SibSp: string, Parch: string, Ticket: string, Fare: string, Cabin: string, Embarked: string, Mark: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: double (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: double (nullable = true)\n",
      " |-- Parch: double (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Mark: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert Age, SibSp, Parch, Fare to Numeric\n",
    "df = (df.withColumn('Age',df['Age'].cast(\"double\"))\n",
    "            .withColumn('SibSp',df['SibSp'].cast(\"double\"))\n",
    "            .withColumn('Parch',df['Parch'].cast(\"double\"))\n",
    "            .withColumn('Fare',df['Fare'].cast(\"double\"))\n",
    "            .withColumn('Survived',df['Survived'].cast(\"double\"))\n",
    "            )\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| mark|count|\n",
      "+-----+-----+\n",
      "|train|  891|\n",
      "| test|  418|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('mark').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing Age and Fare with the Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numVars = ['Survived','Age','SibSp','Parch','Fare']\n",
    "def countNull(df, var):\n",
    "    return df.where(df[var].isNull()).count()\n",
    " \n",
    "missing = {var: countNull(df,var) for var in numVars}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': 263, 'Fare': 1, 'Parch': 0, 'SibSp': 0, 'Survived': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mean = df.groupBy().mean('Age').first()[0]\n",
    "fare_mean = df.groupBy().mean('Fare').first()[0]\n",
    "df = df.na.fill({'Age':age_mean,'Fare':fare_mean, 'Parch':0, 'Sex':'male', 'Embarked': 'S'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': 0, 'Fare': 0, 'Parch': 0, 'SibSp': 0, 'Survived': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = {var: countNull(df, var) for var in numVars}\n",
    "missing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Impute missing Embark\n",
    "\n",
    "df = df.na.fill({'Embarked': 'S'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+-----+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|               Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked| Mark|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+-----+\n",
      "|          1|     0.0|     3|Braund, Mr. Owen ...|  male|              22.0|  1.0|  0.0|       A/5 21171|   7.25| null|       S|train|\n",
      "|          2|     1.0|     1|Cumings, Mrs. Joh...|female|              38.0|  1.0|  0.0|        PC 17599|71.2833|  C85|       C|train|\n",
      "|          3|     1.0|     3|Heikkinen, Miss. ...|female|              26.0|  0.0|  0.0|STON/O2. 3101282|  7.925| null|       S|train|\n",
      "|          4|     1.0|     1|Futrelle, Mrs. Ja...|female|              35.0|  1.0|  0.0|          113803|   53.1| C123|       S|train|\n",
      "|          5|     0.0|     3|Allen, Mr. Willia...|  male|              35.0|  0.0|  0.0|          373450|   8.05| null|       S|train|\n",
      "|          6|     0.0|     3|    Moran, Mr. James|  male|29.881137667304014|  0.0|  0.0|          330877| 8.4583| null|       Q|train|\n",
      "|          7|     0.0|     1|McCarthy, Mr. Tim...|  male|              54.0|  0.0|  0.0|           17463|51.8625|  E46|       S|train|\n",
      "|          8|     0.0|     3|Palsson, Master. ...|  male|               2.0|  3.0|  1.0|          349909| 21.075| null|       S|train|\n",
      "|          9|     1.0|     3|Johnson, Mrs. Osc...|female|              27.0|  0.0|  2.0|          347742|11.1333| null|       S|train|\n",
      "|         10|     1.0|     2|Nasser, Mrs. Nich...|female|              14.0|  1.0|  0.0|          237736|30.0708| null|       C|train|\n",
      "|         11|     1.0|     3|Sandstrom, Miss. ...|female|               4.0|  1.0|  1.0|         PP 9549|   16.7|   G6|       S|train|\n",
      "|         12|     1.0|     1|Bonnell, Miss. El...|female|              58.0|  0.0|  0.0|          113783|  26.55| C103|       S|train|\n",
      "|         13|     0.0|     3|Saundercock, Mr. ...|  male|              20.0|  0.0|  0.0|       A/5. 2151|   8.05| null|       S|train|\n",
      "|         14|     0.0|     3|Andersson, Mr. An...|  male|              39.0|  1.0|  5.0|          347082| 31.275| null|       S|train|\n",
      "|         15|     0.0|     3|Vestrom, Miss. Hu...|female|              14.0|  0.0|  0.0|          350406| 7.8542| null|       S|train|\n",
      "|         16|     1.0|     2|Hewlett, Mrs. (Ma...|female|              55.0|  0.0|  0.0|          248706|   16.0| null|       S|train|\n",
      "|         17|     0.0|     3|Rice, Master. Eugene|  male|               2.0|  4.0|  1.0|          382652| 29.125| null|       Q|train|\n",
      "|         18|     1.0|     2|Williams, Mr. Cha...|  male|29.881137667304014|  0.0|  0.0|          244373|   13.0| null|       S|train|\n",
      "|         19|     0.0|     3|Vander Planke, Mr...|female|              31.0|  1.0|  0.0|          345763|   18.0| null|       S|train|\n",
      "|         20|     1.0|     3|Masselmani, Mrs. ...|female|29.881137667304014|  0.0|  0.0|            2649|  7.225| null|       C|train|\n",
      "+-----------+--------+------+--------------------+------+------------------+-----+-----+----------------+-------+-----+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Title from Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|                Name|          Title|\n",
      "+--------------------+---------------+\n",
      "|Braund, Mr. Owen ...|     Braund, Mr|\n",
      "|Cumings, Mrs. Joh...|   Cumings, Mrs|\n",
      "|Heikkinen, Miss. ...|Heikkinen, Miss|\n",
      "+--------------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    " \n",
    "## created user defined function to extract title\n",
    "getTitle = udf(lambda name: name.split('.')[0].strip(),StringType())\n",
    "df = df.withColumn('Title', getTitle(df['Name']))\n",
    " \n",
    "df.select('Name','Title').show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|   Sex|\n",
      "+------+\n",
      "|  male|\n",
      "|female|\n",
      "|female|\n",
      "|female|\n",
      "|  male|\n",
      "|  male|\n",
      "|  male|\n",
      "|  male|\n",
      "|female|\n",
      "|female|\n",
      "|female|\n",
      "|female|\n",
      "|  male|\n",
      "|  male|\n",
      "|female|\n",
      "|female|\n",
      "|  male|\n",
      "|  male|\n",
      "|female|\n",
      "|female|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Sex').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## index Sex variable\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "si = StringIndexer(inputCol = 'Sex', outputCol = 'Sex_indexed')\n",
    "df_indexed = si.fit(df).transform(df).drop('Sex').withColumnRenamed('Sex_indexed','Sex')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|Sex|\n",
      "+---+\n",
      "|0.0|\n",
      "|1.0|\n",
      "|1.0|\n",
      "|1.0|\n",
      "|0.0|\n",
      "+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_indexed.select('Sex').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+\n",
      "|Embarked|Embarked_indexed|\n",
      "+--------+----------------+\n",
      "|       S|             0.0|\n",
      "|       C|             1.0|\n",
      "|       S|             0.0|\n",
      "+--------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## make use of pipeline to index all categorical variables\n",
    "catVars = ['Pclass','Sex','Embarked','Title']\n",
    "  \n",
    "## make use of pipeline to index all categorical variables\n",
    "def indexer(df,col):\n",
    "    si = StringIndexer(inputCol = col, outputCol = col+'_indexed').fit(df)\n",
    "    return si\n",
    " \n",
    "indexers = [indexer(df,col) for col in catVars]\n",
    " \n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages = indexers)\n",
    "df_indexed = pipeline.fit(df).transform(df)\n",
    " \n",
    "df_indexed.select('Embarked','Embarked_indexed').show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to label/features format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "catVarsIndexed = [i+'_indexed' for i in catVars]\n",
    "featuresCol = numVars+catVarsIndexed\n",
    "featuresCol.remove('Survived')\n",
    "labelCol = ['Mark','Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "row = Row('mark','label','features')\n",
    " \n",
    "df_indexed = df_indexed[labelCol+featuresCol]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+--------------------+\n",
      "| mark|label|            features|\n",
      "+-----+-----+--------------------+\n",
      "|train|  0.0|[22.0,1.0,0.0,7.2...|\n",
      "|train|  1.0|[38.0,1.0,0.0,71....|\n",
      "|train|  1.0|[26.0,0.0,0.0,7.9...|\n",
      "+-----+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0-mark, 1-label, 2-features\n",
    "# map features to DenseVector\n",
    "lf = df_indexed.rdd.map(lambda r: (row(r[0], r[1], Vectors.dense(r[2:])))).toDF()\n",
    "# index label\n",
    "\n",
    " \n",
    "lf.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numeric label to categorical, which is required by\n",
    "# decisionTree and randomForest\n",
    "lf = StringIndexer(inputCol = 'label',outputCol='index').fit(lf).transform(lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+--------------------+-----+\n",
      "| mark|label|            features|index|\n",
      "+-----+-----+--------------------+-----+\n",
      "|train|  0.0|[22.0,1.0,0.0,7.2...|  0.0|\n",
      "|train|  1.0|[38.0,1.0,0.0,71....|  1.0|\n",
      "|train|  1.0|[26.0,0.0,0.0,7.9...|  1.0|\n",
      "|train|  1.0|[35.0,1.0,0.0,53....|  1.0|\n",
      "|train|  0.0|[35.0,0.0,0.0,8.0...|  0.0|\n",
      "|train|  0.0|[29.8811376673040...|  0.0|\n",
      "|train|  0.0|[54.0,0.0,0.0,51....|  0.0|\n",
      "|train|  0.0|[2.0,3.0,1.0,21.0...|  0.0|\n",
      "|train|  1.0|[27.0,0.0,2.0,11....|  1.0|\n",
      "|train|  1.0|[14.0,1.0,0.0,30....|  1.0|\n",
      "|train|  1.0|[4.0,1.0,1.0,16.7...|  1.0|\n",
      "|train|  1.0|[58.0,0.0,0.0,26....|  1.0|\n",
      "|train|  0.0|[20.0,0.0,0.0,8.0...|  0.0|\n",
      "|train|  0.0|[39.0,1.0,5.0,31....|  0.0|\n",
      "|train|  0.0|[14.0,0.0,0.0,7.8...|  0.0|\n",
      "|train|  1.0|[55.0,0.0,0.0,16....|  1.0|\n",
      "|train|  0.0|[2.0,4.0,1.0,29.1...|  0.0|\n",
      "|train|  1.0|[29.8811376673040...|  1.0|\n",
      "|train|  0.0|[31.0,1.0,0.0,18....|  0.0|\n",
      "|train|  1.0|[29.8811376673040...|  1.0|\n",
      "+-----+-----+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| mark|count|\n",
      "+-----+-----+\n",
      "|train|  891|\n",
      "| test|  418|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lf.groupBy('mark').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = lf.where(lf.mark =='train')\n",
    "test = lf.where(lf.mark =='test')\n",
    " \n",
    "# random split further to get train/validate\n",
    "train,validate = train.randomSplit([0.7,0.3],seed =121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Number of Row: 637\n",
      "Validate Data Number of Row: 254\n",
      "Test Data Number of Row: 418\n"
     ]
    }
   ],
   "source": [
    "print('Train Data Number of Row: '+ str(train.count()))\n",
    "print('Validate Data Number of Row: '+ str(validate.count()))\n",
    "print('Test Data Number of Row: '+ str(test.count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.select('index','features').rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Models from ML/MLLIB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC of Logistic Regression model is: 0.8160377358490569\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    " \n",
    "# regPara: lasso regularisation parameter (L1)\n",
    "lr = LogisticRegression(maxIter = 100, regParam = 0.05, labelCol='index').fit(train.select('index','features'))\n",
    " \n",
    "# Evaluate model based on auc ROC(default for binary classification)\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    " \n",
    "def testModel(model, validate = validate):\n",
    "    pred = model.transform(validate)\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol = 'index')\n",
    "    return evaluator.evaluate(pred)\n",
    " \n",
    "print ('AUC ROC of Logistic Regression model is: '+str(testModel(lr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n",
    " \n",
    "dt = DecisionTreeClassifier(maxDepth = 5, labelCol ='index').fit(train)\n",
    "rf = RandomForestClassifier(numTrees = 10, labelCol = 'index').fit(train)\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'LogisticRegression':lr,\n",
    "          'DecistionTree':dt,\n",
    "          'RandomForest':rf}\n",
    " \n",
    "modelPerf = {k:testModel(v) for k,v in models.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DecistionTree': 0.5789775624681285,\n",
       " 'LogisticRegression': 0.8160377358490568,\n",
       " 'RandomForest': 0.8465068842427337}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelPerf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
